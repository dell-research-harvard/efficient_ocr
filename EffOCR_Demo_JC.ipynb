{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Logo](assets/effocr_logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation and Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Installing EffOCR is easy with `pip`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install efficient_ocr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the remainder of the demo, we'll need import the main `EffOCR` class, as well as a few other helpful libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmXc319MV2zf"
      },
      "outputs": [],
      "source": [
        "from efficient_ocr import EffOCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\n",
        "# import ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRakAoXpX0g3"
      },
      "source": [
        "## EffOCR Configs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Whether you're running training or inference with EffOCR, you'll need to speciy a config! Fortunately, EffOCR only requires you directly specify a single config file in `YAML` format. (If you want to use MMDetection as a backend for object detection, you'll also need an MMDetection config file as well.)\n",
        "\n",
        "Here's how it looks, for example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "k7CSp5uHYF3u"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---\n",
            "Global:\n",
            "  char_only: false\n",
            "  recognition_only: false\n",
            "  wandb_project: name_of_wandb_project_for_effocr\n",
            "Line:\n",
            "  batch_size: 16\n",
            "  conf_thresh: 0.2\n",
            "  device: cpu\n",
            "  epochs: 50\n",
            "  input_shape: (640, 640)\n",
            "  iou_thresh: 0.15\n",
            "  max_det: 200\n",
            "  min_seg_ratio: 2\n",
            "  model_backend: yolo\n",
            "  model_path: /path/to/line/detection/model\n",
            "  num_cores: null\n",
            "  providers: null\n",
            "  training_name: name_of_training_run\n",
            "  visualize: null\n",
            "Localizer:\n",
            "  batch_size: 16\n",
            "  conf_thresh: 0.25\n",
            "  device: cpu\n",
            "  epochs: 50\n",
            "  input_shape: (640, 640)\n",
            "  iou_thresh: 0.1\n",
            "  max_det: 200\n",
            "  mmdet_config: null\n",
            "  model_backend: yolo\n",
            "  model_path: /path/to/localizer/model\n",
            "  num_cores: null\n",
            "  onnx_providers: null\n",
            "  training_name: name_of_training_run\n",
            "  vertical: false\n",
            "  visualize: null\n",
            "Recognizer:\n",
            "  char:\n",
            "    adamw_beta1: 0.9\n",
            "    adamw_beta2: 0.999\n",
            "    ascender: true\n",
            "    aug_paired: false\n",
            "    batch_size: 128\n",
            "    char_only_sampler: false\n",
            "    char_trans_version: 2\n",
            "    dec_lr_factor: 0.9\n",
            "    default_font_name: Noto\n",
            "    diff_sizes: false\n",
            "    epoch_viz_dir: null\n",
            "    expansion_factor: 1\n",
            "    few_shot: null\n",
            "    finetune: false\n",
            "    font_dir_path: /path/to/dir/of/font/files/for/synthetic/rendering\n",
            "    hardneg_k: 8\n",
            "    high_blur: false\n",
            "    hns_txt_path: null\n",
            "    imsize: 224\n",
            "    int_eval_steps: null\n",
            "    latin_suggested_augs: true\n",
            "    lr: 0.002\n",
            "    lr_schedule: false\n",
            "    m: 4\n",
            "    model_backend: timm\n",
            "    model_output_dir: /path/to/char/model/output\n",
            "    no_aug: false\n",
            "    num_cores: null\n",
            "    num_epochs: 20\n",
            "    num_passes: 1\n",
            "    pretrain: false\n",
            "    pretrained_model_dir: /path/to/pretrained/model/output/dir\n",
            "    providers: null\n",
            "    ready_to_go_data_dir_path: /path/to/dir/of/preformed/training/data/from/previous/run\n",
            "    render_dict:\n",
            "    - /path/to/list/of/chars/to/render\n",
            "    - /another/path/to/list/of/chars/to/render\n",
            "    start_epoch: 1\n",
            "    temp: 0.1\n",
            "    test_at_end: true\n",
            "    test_set_from_coco_json: null\n",
            "    timm_model_name: mobilenetv3_small_050.lamb_in1k\n",
            "    train_set_from_coco_json: null\n",
            "    train_val_test_split:\n",
            "    - 0.7\n",
            "    - 0.15\n",
            "    - 0.15\n",
            "    val_set_from_coco_json: null\n",
            "    weight_decay: 0.0005\n",
            "  word:\n",
            "    adamw_beta1: 0.9\n",
            "    adamw_beta2: 0.999\n",
            "    ascender: true\n",
            "    aug_paired: false\n",
            "    batch_size: 128\n",
            "    char_only_sampler: false\n",
            "    char_trans_version: 2\n",
            "    dec_lr_factor: 0.9\n",
            "    default_font_name: Noto\n",
            "    diff_sizes: false\n",
            "    epoch_viz_dir: null\n",
            "    expansion_factor: 1\n",
            "    few_shot: null\n",
            "    finetune: false\n",
            "    font_dir_path: /path/to/dir/of/font/files/for/synthetic/rendering\n",
            "    hardneg_k: 8\n",
            "    high_blur: false\n",
            "    hns_txt_path: null\n",
            "    imsize: 224\n",
            "    int_eval_steps: null\n",
            "    latin_suggested_augs: true\n",
            "    lr: 0.002\n",
            "    lr_schedule: false\n",
            "    m: 4\n",
            "    model_backend: timm\n",
            "    model_output_dir: /path/to/word/model/output\n",
            "    no_aug: false\n",
            "    num_cores: null\n",
            "    num_epochs: 20\n",
            "    num_passes: 1\n",
            "    pretrain: false\n",
            "    pretrained_model_dir: /path/to/pretrained/model/output/dir\n",
            "    providers: null\n",
            "    ready_to_go_data_dir_path: /path/to/dir/of/preformed/training/data/from/previous/run\n",
            "    render_dict:\n",
            "    - /path/to/list/of/words/to/render\n",
            "    - /another/path/to/list/of/words/to/render\n",
            "    start_epoch: 1\n",
            "    temp: 0.1\n",
            "    test_at_end: true\n",
            "    test_set_from_coco_json: null\n",
            "    timm_model_name: mobilenetv3_small_050.lamb_in1k\n",
            "    train_set_from_coco_json: null\n",
            "    train_val_test_split:\n",
            "    - 0.7\n",
            "    - 0.15\n",
            "    - 0.15\n",
            "    val_set_from_coco_json: null\n",
            "    weight_decay: 0.0005\n",
            "\n"
          ]
        }
      ],
      "source": [
        "with open('./config/config_dummy.yaml') as f:\n",
        "    print(yaml.safe_dump(yaml.safe_load(f), explicit_start=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Some fields are self-explanatory, others are not! Visit the documentation on our GitHub repo to learn more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K20vG2UWuhY"
      },
      "source": [
        "## (Zero-Shot) Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sample-Efficient Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "effocr = EffOCR(\n",
        "        data_json, data_dir, config_yaml\n",
        "    )\n",
        "\n",
        "    effocr.train(target=['word_recognition', 'char_recognition'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI3ZclcJWxiv"
      },
      "source": [
        " (Few-Shot Learning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBc3FfeoXnAd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbSIj2LJYaJM"
      },
      "source": [
        "## 3. End-to-End Training"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
