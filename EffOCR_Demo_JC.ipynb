{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Logo](assets/effocr_logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation and Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Installing EffOCR is easy with `pip`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install efficient_ocr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the remainder of the demo, we'll need import the main `EffOCR` class, as well as a few other helpful libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmXc319MV2zf"
      },
      "outputs": [],
      "source": [
        "from efficient_ocr import EffOCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\n",
        "# import ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRakAoXpX0g3"
      },
      "source": [
        "## EffOCR Configs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Whether you're running training or inference with EffOCR, you'll need to speciy a config! Fortunately, EffOCR only requires you directly specify a single config file in `YAML` format. (If you want to use MMDetection as a backend for object detection, you'll also need an MMDetection config file as well.)\n",
        "\n",
        "Here's how it looks, for example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "k7CSp5uHYF3u"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---\n",
            "Global:\n",
            "  char_only: false\n",
            "  language: en\n",
            "  recognition_only: false\n",
            "  wandb_project: effocr_package_test_locca\n",
            "Line:\n",
            "  batch_size: 16\n",
            "  conf_thresh: 0.2\n",
            "  device: cpu\n",
            "  epochs: 50\n",
            "  input_shape: (640, 640)\n",
            "  iou_thresh: 0.15\n",
            "  max_det: 200\n",
            "  min_seg_ratio: 2\n",
            "  model_backend: yolo\n",
            "  model_path: ./models/yolo/line_model.pt\n",
            "  num_cores: null\n",
            "  providers: null\n",
            "  training_name: effocr_line\n",
            "  visualize: null\n",
            "Localizer:\n",
            "  batch_size: 16\n",
            "  conf_thresh: 0.25\n",
            "  device: cpu\n",
            "  epochs: 50\n",
            "  input_shape: (640, 640)\n",
            "  iou_thresh: 0.1\n",
            "  language: en\n",
            "  max_det: 200\n",
            "  mmdet_config: null\n",
            "  model_backend: yolo\n",
            "  model_path: ./models/yolo/localizer_model.pt\n",
            "  num_cores: null\n",
            "  onnx_providers: null\n",
            "  training_name: effocr_localizer\n",
            "  vertical: false\n",
            "  visualize: null\n",
            "Recognizer:\n",
            "  char:\n",
            "    adamw_beta1: 0.9\n",
            "    adamw_beta2: 0.999\n",
            "    ascender: true\n",
            "    aug_paired: false\n",
            "    batch_size: 128\n",
            "    char_only_sampler: false\n",
            "    char_trans_version: 2\n",
            "    dec_lr_factor: 0.9\n",
            "    default_font_name: Noto\n",
            "    diff_sizes: false\n",
            "    epoch_viz_dir: null\n",
            "    expansion_factor: 1\n",
            "    few_shot: null\n",
            "    finetune: false\n",
            "    font_dir_path: /mnt/122a7683-fa4b-45dd-9f13-b18cc4f4a187/jake_github_repos/ocr-as-retrieval/english_font_files\n",
            "    hardneg_k: 8\n",
            "    high_blur: false\n",
            "    hns_txt_path: null\n",
            "    imsize: 224\n",
            "    int_eval_steps: null\n",
            "    latin_suggested_augs: true\n",
            "    lr: 0.002\n",
            "    lr_schedule: false\n",
            "    m: 4\n",
            "    model_backend: onnx\n",
            "    model_output_dir: ./effocr_package_test_locca_char2\n",
            "    no_aug: false\n",
            "    num_cores: null\n",
            "    num_epochs: 30\n",
            "    num_passes: 40\n",
            "    pretrain: false\n",
            "    pretrained_model_dir: ./models/yolo/char_recognizer\n",
            "    providers: null\n",
            "    ready_to_go_data_dir_path: /mnt/122a7683-fa4b-45dd-9f13-b18cc4f4a187/ocr_char_crops/locca\n",
            "    render_dict:\n",
            "    - /mnt/122a7683-fa4b-45dd-9f13-b18cc4f4a187/jake_github_repos/ocr-as-retrieval/english_charsets/allchars.txt\n",
            "    start_epoch: 1\n",
            "    temp: 0.1\n",
            "    test_at_end: true\n",
            "    test_set_from_coco_json: null\n",
            "    timm_model_name: mobilenetv3_small_050.lamb_in1k\n",
            "    train_set_from_coco_json: null\n",
            "    train_val_test_split:\n",
            "    - 0.7\n",
            "    - 0.15\n",
            "    - 0.15\n",
            "    val_set_from_coco_json: null\n",
            "    weight_decay: 0.0005\n",
            "  word:\n",
            "    adamw_beta1: 0.9\n",
            "    adamw_beta2: 0.999\n",
            "    ascender: true\n",
            "    aug_paired: false\n",
            "    batch_size: 256\n",
            "    char_only_sampler: false\n",
            "    char_trans_version: 2\n",
            "    dec_lr_factor: 0.9\n",
            "    default_font_name: Noto\n",
            "    diff_sizes: false\n",
            "    epoch_viz_dir: null\n",
            "    expansion_factor: 1\n",
            "    few_shot: null\n",
            "    finetune: false\n",
            "    font_dir_path: /mnt/122a7683-fa4b-45dd-9f13-b18cc4f4a187/jake_github_repos/ocr-as-retrieval/english_font_files\n",
            "    hardneg_k: 8\n",
            "    high_blur: false\n",
            "    hns_txt_path: null\n",
            "    imsize: 224\n",
            "    int_eval_steps: null\n",
            "    latin_suggested_augs: true\n",
            "    lr: 0.002\n",
            "    lr_schedule: false\n",
            "    m: 4\n",
            "    model_backend: onnx\n",
            "    model_output_dir: ./effocr_package_test_locca_word2\n",
            "    no_aug: false\n",
            "    num_cores: null\n",
            "    num_epochs: 1\n",
            "    num_passes: 1\n",
            "    pretrain: false\n",
            "    pretrained_model_dir: ./models/yolo/word_recognizer_new\n",
            "    providers: null\n",
            "    ready_to_go_data_dir_path: /mnt/122a7683-fa4b-45dd-9f13-b18cc4f4a187/word_level_effocr/fullsym_locc_dict_words_paired_silver/images\n",
            "    render_dict:\n",
            "    - /mnt/122a7683-fa4b-45dd-9f13-b18cc4f4a187/e2e2e/end-to-end-pipeline/pipeline_egress/silver_dpd/full_wordlist_effocr.txt\n",
            "    start_epoch: 1\n",
            "    temp: 0.1\n",
            "    test_at_end: true\n",
            "    test_set_from_coco_json: null\n",
            "    timm_model_name: mobilenetv3_small_050.lamb_in1k\n",
            "    train_set_from_coco_json: null\n",
            "    train_val_test_split:\n",
            "    - 0.7\n",
            "    - 0.15\n",
            "    - 0.15\n",
            "    val_set_from_coco_json: null\n",
            "    weight_decay: 0.0005\n",
            "\n"
          ]
        }
      ],
      "source": [
        "with open('./config/config_dummy.yaml') as f:\n",
        "    print(yaml.safe_dump(yaml.safe_load(f), explicit_start=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K20vG2UWuhY"
      },
      "source": [
        "## 1. Zero Shot Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiaJKt7SYoeL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9T_zd33V0RD"
      },
      "outputs": [],
      "source": [
        "### Demonstrate Zero Shot capabilities\n",
        "\n",
        "### Read Images (find friendly examples)\n",
        "img = cv2.imread(XXXX)\n",
        "\n",
        "### Display within notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuP40uUDY7xt"
      },
      "outputs": [],
      "source": [
        "engine = effocr.EffOCR(config = 'path/to/config.yaml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fe3p_zqKWTm9"
      },
      "outputs": [],
      "source": [
        "# Run EffOCR\n",
        "result = engine.infer(img)\n",
        "\n",
        "# Display results\n",
        "print(result.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6WzdW7CWbAV"
      },
      "outputs": [],
      "source": [
        "# Show Visualization\n",
        "img = effocr.display_detections(img, result.preds)\n",
        "display(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI3ZclcJWxiv"
      },
      "source": [
        "## 2. Few Shot Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBc3FfeoXnAd"
      },
      "outputs": [],
      "source": [
        "### Show"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbSIj2LJYaJM"
      },
      "source": [
        "## 3. End-to-End Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yO0fKeV3YcIu"
      },
      "outputs": [],
      "source": [
        "### Show data json, image folder, demonstrate full training"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
