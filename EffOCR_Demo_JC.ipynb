{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Logo](assets/effocr_logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EfficientOCR (EffOCR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Welcome to the EffOCR demo! [EffOCR](https://arxiv.org/abs/2304.02737) is a new architecture for \n",
        "\n",
        "- sample efficient and\n",
        "- computationally efficient \n",
        "\n",
        "OCR, newly implemented as Python package.\n",
        "\n",
        "Let's check it out!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation and Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Installing EffOCR is easy with `pip`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install efficient_ocr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the remainder of the demo, we'll need import the main `EffOCR` class, as well as a few other helpful libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmXc319MV2zf"
      },
      "outputs": [],
      "source": [
        "from efficient_ocr import EffOCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\n",
        "# import ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRakAoXpX0g3"
      },
      "source": [
        "## Configs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Whether you're running training or inference with EffOCR, you'll need to speciy a config. Fortunately, EffOCR only requires you directly specify a single config file in `YAML` format. (If you want to use MMDetection as a backend for object detection, you'll also need an MMDetection config file as well.)\n",
        "\n",
        "Here's how it looks, for example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "k7CSp5uHYF3u"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---\n",
            "Global:\n",
            "  char_only: false\n",
            "  recognition_only: false\n",
            "  wandb_project: name_of_wandb_project_for_effocr\n",
            "Line:\n",
            "  batch_size: 16\n",
            "  conf_thresh: 0.2\n",
            "  device: cpu\n",
            "  epochs: 50\n",
            "  input_shape: (640, 640)\n",
            "  iou_thresh: 0.15\n",
            "  max_det: 200\n",
            "  min_seg_ratio: 2\n",
            "  model_backend: yolo\n",
            "  model_path: /path/to/line/detection/model\n",
            "  num_cores: null\n",
            "  providers: null\n",
            "  training_name: name_of_training_run\n",
            "  visualize: null\n",
            "Localizer:\n",
            "  batch_size: 16\n",
            "  conf_thresh: 0.25\n",
            "  device: cpu\n",
            "  epochs: 50\n",
            "  input_shape: (640, 640)\n",
            "  iou_thresh: 0.1\n",
            "  max_det: 200\n",
            "  mmdet_config: null\n",
            "  model_backend: yolo\n",
            "  model_path: /path/to/localizer/model\n",
            "  num_cores: null\n",
            "  onnx_providers: null\n",
            "  training_name: name_of_training_run\n",
            "  vertical: false\n",
            "  visualize: null\n",
            "Recognizer:\n",
            "  char:\n",
            "    adamw_beta1: 0.9\n",
            "    adamw_beta2: 0.999\n",
            "    ascender: true\n",
            "    aug_paired: false\n",
            "    batch_size: 128\n",
            "    char_only_sampler: false\n",
            "    char_trans_version: 2\n",
            "    dec_lr_factor: 0.9\n",
            "    default_font_name: Noto\n",
            "    diff_sizes: false\n",
            "    epoch_viz_dir: null\n",
            "    expansion_factor: 1\n",
            "    few_shot: null\n",
            "    finetune: false\n",
            "    font_dir_path: /path/to/dir/of/font/files/for/synthetic/rendering\n",
            "    hardneg_k: 8\n",
            "    high_blur: false\n",
            "    hns_txt_path: null\n",
            "    imsize: 224\n",
            "    int_eval_steps: null\n",
            "    latin_suggested_augs: true\n",
            "    lr: 0.002\n",
            "    lr_schedule: false\n",
            "    m: 4\n",
            "    model_backend: timm\n",
            "    model_output_dir: /path/to/char/model/output\n",
            "    no_aug: false\n",
            "    num_cores: null\n",
            "    num_epochs: 20\n",
            "    num_passes: 1\n",
            "    pretrain: false\n",
            "    pretrained_model_dir: /path/to/pretrained/model/output/dir\n",
            "    providers: null\n",
            "    ready_to_go_data_dir_path: /path/to/dir/of/preformed/training/data/from/previous/run\n",
            "    render_dict:\n",
            "    - /path/to/list/of/chars/to/render\n",
            "    - /another/path/to/list/of/chars/to/render\n",
            "    start_epoch: 1\n",
            "    temp: 0.1\n",
            "    test_at_end: true\n",
            "    test_set_from_coco_json: null\n",
            "    timm_model_name: mobilenetv3_small_050.lamb_in1k\n",
            "    train_set_from_coco_json: null\n",
            "    train_val_test_split:\n",
            "    - 0.7\n",
            "    - 0.15\n",
            "    - 0.15\n",
            "    val_set_from_coco_json: null\n",
            "    weight_decay: 0.0005\n",
            "  word:\n",
            "    adamw_beta1: 0.9\n",
            "    adamw_beta2: 0.999\n",
            "    ascender: true\n",
            "    aug_paired: false\n",
            "    batch_size: 128\n",
            "    char_only_sampler: false\n",
            "    char_trans_version: 2\n",
            "    dec_lr_factor: 0.9\n",
            "    default_font_name: Noto\n",
            "    diff_sizes: false\n",
            "    epoch_viz_dir: null\n",
            "    expansion_factor: 1\n",
            "    few_shot: null\n",
            "    finetune: false\n",
            "    font_dir_path: /path/to/dir/of/font/files/for/synthetic/rendering\n",
            "    hardneg_k: 8\n",
            "    high_blur: false\n",
            "    hns_txt_path: null\n",
            "    imsize: 224\n",
            "    int_eval_steps: null\n",
            "    latin_suggested_augs: true\n",
            "    lr: 0.002\n",
            "    lr_schedule: false\n",
            "    m: 4\n",
            "    model_backend: timm\n",
            "    model_output_dir: /path/to/word/model/output\n",
            "    no_aug: false\n",
            "    num_cores: null\n",
            "    num_epochs: 20\n",
            "    num_passes: 1\n",
            "    pretrain: false\n",
            "    pretrained_model_dir: /path/to/pretrained/model/output/dir\n",
            "    providers: null\n",
            "    ready_to_go_data_dir_path: /path/to/dir/of/preformed/training/data/from/previous/run\n",
            "    render_dict:\n",
            "    - /path/to/list/of/words/to/render\n",
            "    - /another/path/to/list/of/words/to/render\n",
            "    start_epoch: 1\n",
            "    temp: 0.1\n",
            "    test_at_end: true\n",
            "    test_set_from_coco_json: null\n",
            "    timm_model_name: mobilenetv3_small_050.lamb_in1k\n",
            "    train_set_from_coco_json: null\n",
            "    train_val_test_split:\n",
            "    - 0.7\n",
            "    - 0.15\n",
            "    - 0.15\n",
            "    val_set_from_coco_json: null\n",
            "    weight_decay: 0.0005\n",
            "\n"
          ]
        }
      ],
      "source": [
        "with open('./config/config_dummy.yaml') as f:\n",
        "    print(yaml.safe_dump(yaml.safe_load(f), explicit_start=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Some fields are self-explanatory, others are not! Visit the documentation on our GitHub repo to learn more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K20vG2UWuhY"
      },
      "source": [
        "## (Zero-Shot) Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Many will want to use EffOCR right off the shelf for zero-shot inference purposes. Our package makes this easy to accommodate in just `X`` lines of code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example: Inference on Archival Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In particular, the digitization of archival content will be of interest to many in the social sciences and (digital) humanities. To showcase the zero-shot capabilities of one of our models trained on mixed English print from archival and historical sources, we apply it to..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sample-Efficient Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "EffOCR is a sample efficient OCR architecture, and our package let's you train EffOCR yourself to take advantage of it! You can accomplish this in just `2` lines of code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "effocr = EffOCR(data_json, data_dir, config_yaml)\n",
        "effocr.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, to fully train EffOCR, you only need `3` inputs:\n",
        "\n",
        "1. `data_json = /path/to/coco/json`: a single COCO-style JSON file with annotations for words (or equivalent orthographic units), characters, and lines. (N.B. we provide an example config file for a popular image annotation service to help you get started on creating your own annotations from scratch on your own dataset!)\n",
        "2. `data_dir = /path/to/coco/images/dir`: a single directory containing the images you annotated. \n",
        "3. `config_yaml = /path/to/config/yaml`: an EffOCR YAML config file. \n",
        "\n",
        "That's it! `EffOCR` does the rest, training all four modules in EffOCR."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also just train certain modules within your EffOCR model, e.g., to just train the localizer and line detection modules:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "effocr = EffOCR(data_json, data_dir, config_yaml)\n",
        "effocr.train(target=['line_detection', 'word_and_character_detection'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI3ZclcJWxiv"
      },
      "source": [
        "### Example: Few-Shot Learning in Historical Japanese"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In practice, we suspect that many people will be interested in training and fine-tuning their own EffOCR recognizer modules. One use case we've been interested is the digitization of historical Japanese firm-level reports, with data of interest being in tables, with text oriented vertically. \n",
        "\n",
        "Because of the low-resourceness of this setting, the best available alternative to EffOCR gets a CER of 55.6%! But with just a `1` training sample across a few hundred kanji, EffOCR achieves just a CER of X%!\n",
        "\n",
        "To use EffOCR for few-shot learning, just specify \n",
        "```YAML\n",
        "Recognizer:\n",
        "  char:\n",
        "    few_shot: 10\n",
        "```\n",
        "in the config, and train on the relevant modules, once the relevant data has been assembled!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBc3FfeoXnAd"
      },
      "outputs": [],
      "source": [
        "effocr = EffOCR(data_json, data_dir, config_yaml)\n",
        "effocr.train(target=['char_recognition'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inference and visualization with the newly trained model is super easy to perform, as shown before!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The upload to the HF model hub!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
